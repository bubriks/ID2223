{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bubriks/ID2223/blob/main/Lab2/lab-2_colab-version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXAsTICnCOE8"
      },
      "source": [
        "# **LAB-2: Scalable Machine Learning and Deep Learning**\n",
        "\n",
        "## **Paolo Teta & Ralfs Zangis**\n",
        "---\n",
        "**TASK:** Implement **S-BERT** model\n",
        "\n",
        "**Outline:**\n",
        "- Load the dataset\n",
        "- Regression\n",
        "- Classification\n",
        "- Evaluation with STS benchmark dataset (cosine similarity and Spearmean correlation)\n",
        "- Semantic search\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMEMBER:** UPLOAD DATA TO SESSION STORAGE (*sts-benchmark* and *news*)"
      ],
      "metadata": {
        "id": "bt_XZ3rKk4Li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Requirements**"
      ],
      "metadata": {
        "id": "rnSVIDnel6l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies"
      ],
      "metadata": {
        "id": "8uAa95NKjhyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yugvCJ05CMg9"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install torch\n",
        "!pip install wget\n",
        "\n",
        "# !pip install pyspark\n",
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.sql.functions import *\n",
        "# from pyspark.sql.types import *\n",
        "# spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import wget\n",
        "import json\n",
        "import math\n",
        "import scipy\n",
        "import torch\n",
        "import string\n",
        "import sklearn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers import LoggingHandler\n",
        "from sentence_transformers import models, losses, util\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import InputExample\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "# from transformers import DistilBertTokenizer, DistilBertModel # -> smaller model\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive to load saved models**"
      ],
      "metadata": {
        "id": "HR1aiNbSpaAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TlNVUAMfpXko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **REGRESSION**"
      ],
      "metadata": {
        "id": "BHTmDfTnpiYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained model \"*bert-base-uncased*\" and word embedding model"
      ],
      "metadata": {
        "id": "IMpYMvXM0Iru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "word_embedding_model = models.Transformer(model_name)"
      ],
      "metadata": {
        "id": "YOi6F9ps0biy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## BERT -> original model\n",
        "# model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "## DistilBERT -> smaller model\n",
        "# model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "9iA52co00tjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the datasets"
      ],
      "metadata": {
        "id": "DKMoZfeDqHOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['title', 'type', 'year', 'id', 'score', 'sentence_1', 'sentence_2']"
      ],
      "metadata": {
        "id": "rS97EOPBzg8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFbZbwrhAmQf"
      },
      "outputs": [],
      "source": [
        "print('Loading train dataset ...')\n",
        "\n",
        "train_path = '/content/sts-train.csv'\n",
        "os.path.isfile(train_path)\n",
        "\n",
        "train_samples = []\n",
        "\n",
        "with open(train_path, newline='') as train:\n",
        "    df_train = csv.DictReader(train, delimiter='\\t', fieldnames=columns, quoting=csv.QUOTE_NONE)\n",
        "    for row in df_train:\n",
        "        score = float(row['score']) / 2.5 - 1 # range -1 ... 1\n",
        "        input_example = InputExample(texts=[row['sentence_1'], row['sentence_2']], label=score)\n",
        "        train_samples.append(input_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqwOffUzOCIh"
      },
      "outputs": [],
      "source": [
        "print('Loading test dataset ...')\n",
        "\n",
        "test_path = '/content/sts-test.csv'\n",
        "os.path.isfile(test_path)\n",
        "\n",
        "test_samples = []\n",
        "\n",
        "with open(test_path, newline='') as test:\n",
        "    df_test = csv.DictReader(test, delimiter='\\t', fieldnames=columns, quoting=csv.QUOTE_NONE)\n",
        "    for row in df_test:\n",
        "        score = float(row['score']) / 2.5 - 1 # range -1 ... 1\n",
        "        input_example = InputExample(texts=[row['sentence_1'], row['sentence_2']], label=score)\n",
        "        test_samples.append(input_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2u5HRNUN9Po"
      },
      "outputs": [],
      "source": [
        "print('Loading evaluation dataset ...')\n",
        "\n",
        "dev_path = '/content/sts-dev.csv'\n",
        "os.path.isfile(dev_path)\n",
        "\n",
        "dev_samples = []\n",
        "\n",
        "with open(dev_path, newline='') as dev:\n",
        "    df_dev = csv.DictReader(dev, delimiter='\\t', fieldnames=columns, quoting=csv.QUOTE_NONE)\n",
        "    for row in df_dev:\n",
        "        score = float(row['score']) / 2.5 - 1 # range -1 ... 1\n",
        "        input_example = InputExample(texts=[row['sentence_1'], row['sentence_2']], label=score)\n",
        "        dev_samples.append(input_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering the given paper \"*Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks*\""
      ],
      "metadata": {
        "id": "HOdKI-S91Yb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epxEtXh2GMYu"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 16\n",
        "# train_batch_size = 32 # try to speed up the training\n",
        "\n",
        "learn_rate = 2e-5\n",
        "num_epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean-pooling strategy"
      ],
      "metadata": {
        "id": "WP5UDhSi2RFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIRLPEnrGhG6"
      },
      "outputs": [],
      "source": [
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model"
      ],
      "metadata": {
        "id": "Fc11KhHR2nH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom model using mean pooling of the word embeddings given as input\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "metadata": {
        "id": "RozMxge52jC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training set and define the loss function as the cosine similarity"
      ],
      "metadata": {
        "id": "tNI9URmg4vCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iht5w4HJlhtt"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss = losses.CosineSimilarityLoss(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the evaluator for the sentence embeddings"
      ],
      "metadata": {
        "id": "NYZlyR-i6z3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JchPxNSDT2f9"
      },
      "outputs": [],
      "source": [
        "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, batch_size=train_batch_size, name='sts-dev')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10% of train dataset for warm-up"
      ],
      "metadata": {
        "id": "yQ2IPb4y7CVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-nlK2kmUCve"
      },
      "outputs": [],
      "source": [
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "0jrrFM8r7Ly9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './training_sts_reg_'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "metadata": {
        "id": "ZbMrmq-11tt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxEXdHtiUDXk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "            optimizer_class=torch.optim.Adam,\n",
        "            optimizer_params={'lr': learn_rate},\n",
        "            evaluator=evaluator,\n",
        "            epochs=num_epochs,\n",
        "            evaluation_steps=1000,\n",
        "            warmup_steps=warmup_steps,\n",
        "            output_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on STS benchmark dataset**\n",
        "\n",
        "Mathematical relationship: *cosine_similarity = 1 - cosine_distance*"
      ],
      "metadata": {
        "id": "foas3A_I981K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz0B_1KpUi3S"
      },
      "outputs": [],
      "source": [
        "print('Loading the stored model ...')\n",
        "model = SentenceTransformer(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv93RESm_tyi"
      },
      "outputs": [],
      "source": [
        "test_eval = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=train_batch_size, name='sts-test')\n",
        "c_s = test_eval(model, output_path=save_path)\n",
        "print('Cosine similarity with the sentence_transformers library = ', c_s)\n",
        "\n",
        "# sometimes the result is between 0.7 and 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding sentences"
      ],
      "metadata": {
        "id": "axyd6hqZ_a5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(test_path, sep='\\t', header=None, error_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
        "df_test.columns = columns"
      ],
      "metadata": {
        "id": "fMDBfVfPHlOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy0C_4qm_tsR"
      },
      "outputs": [],
      "source": [
        "embed_1 = model.encode(df_test['sentence_1'], convert_to_numpy=True, batch_size=train_batch_size)\n",
        "embed_2 = model.encode(df_test['sentence_2'], convert_to_numpy=True, batch_size=train_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the cosine similarity"
      ],
      "metadata": {
        "id": "iv3qFiDeB3uS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9oux_4b_tk_"
      },
      "outputs": [],
      "source": [
        "cos_sim = 1 - sklearn.metrics.pairwise.paired_cosine_distances(embed_1, embed_2)\n",
        "print('Cosine similarity = ', cos_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spearmean correlation coefficient"
      ],
      "metadata": {
        "id": "U4d__O86B9DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spr_corr = scipy.stats.spearmanr(cos_sim, df_test['score'])\n",
        "print('Spearmean correlation coefficient = ', spr_corr[0])"
      ],
      "metadata": {
        "id": "oVziirO7-vHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment:** the two results match each other"
      ],
      "metadata": {
        "id": "XW3C-qqGIcpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fAnrAjHCEMqb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAUh76sD99Y8"
      },
      "source": [
        "## **CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and unzip the dataset"
      ],
      "metadata": {
        "id": "mUw6RHMrRArm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RixFoG2q3EAV"
      },
      "outputs": [],
      "source": [
        "print('Downloading dataset from web ...')\n",
        "\n",
        "url = 'https://nlp.stanford.edu/projects/snli/snli_1.0.zip'\n",
        "\n",
        "if not os.path.exists('./snli_1.0.zip'):\n",
        "    wget.download(url,'./snli_1.0.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvaCK3w3D36"
      },
      "outputs": [],
      "source": [
        "!unzip snli_1.0.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejTmYNmQEp5k"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# convert .json file to .csv file\n",
        "\n",
        "df_train_cl = pd.read_json(r'/content/snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "df_train_cl.to_csv(r'/content/snli_1.0_train.csv', index=None)\n",
        "\n",
        "df_test_cl = pd.read_json(r'/content/snli_1.0/snli_1.0_test.jsonl', lines=True)\n",
        "df_test_cl.to_csv(r'/content/snli_1.0_test.csv', index=None)\n",
        "\n",
        "df_dev_cl = pd.read_json(r'/content/snli_1.0/snli_1.0_dev.jsonl', lines=True)\n",
        "df_dev_cl.to_csv(r'/content/snli_1.0_dev.csv', index=None)\n",
        "\n",
        "\n",
        "\n",
        "train_path = '/content/snli_1.0/snli_1.0_train.jsonl'\n",
        "train_samples = []\n",
        "with open(train_path, newline='') as train:\n",
        "    columns = ['annotator_labels',\n",
        "               'captionID',\n",
        "               'gold_label',\n",
        "               'pairID',\n",
        "               'sentence1', 'sentence1_binary_parse', 'sentence1_parse',\n",
        "               'sentence2', 'sentence2_binary_parse', 'sentence2_parse']\n",
        "    df_train_cl = csv.DictReader(train, delimiter='|', fieldnames=columns, quoting=csv.QUOTE_NONE)\n",
        "    for row in df_train_cl:\n",
        "        inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=row['gold_label'])\n",
        "        train_samples.append(inp_example)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the datasets"
      ],
      "metadata": {
        "id": "tQ5aRvITRG-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdx5qdwlk_I9"
      },
      "outputs": [],
      "source": [
        "print('Loading train dataset ...')\n",
        "train_path = '/content/snli_1.0/snli_1.0_train.jsonl'\n",
        "df_train_cl = pd.read_json(train_path, lines=True)\n",
        "\n",
        "print('Loading test dataset ...')\n",
        "test_path = '/content/snli_1.0/snli_1.0_test.jsonl'\n",
        "df_test_cl = pd.read_json(test_path, lines=True)\n",
        "\n",
        "print('Loading evaluation dataset ...')\n",
        "dev_path = '/content/snli_1.0/snli_1.0_dev.jsonl'\n",
        "df_dev_cl = pd.read_json(dev_path, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PnF6d_iotaj"
      },
      "outputs": [],
      "source": [
        "print(\"Labels in the dataset:\\n\")\n",
        "df_train_cl['gold_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mio6QXcz6xit"
      },
      "outputs": [],
      "source": [
        "df_train_cl['gold_label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert labels to numerical vales"
      ],
      "metadata": {
        "id": "sVwPpye31Pmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWDQJpqaBu9y"
      },
      "outputs": [],
      "source": [
        "label_map = {\"contradiction\": 0,\n",
        "             \"entailment\": 1,\n",
        "             \"neutral\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get rid of the \"-\" label\n",
        "# idx = df_train_cl[df_train_cl['gold_label'] == '-'].index\n",
        "# df_train_cl.drop(idx, inplace=True)"
      ],
      "metadata": {
        "id": "c_j-GfMv50Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afHN7VUd66aF"
      },
      "outputs": [],
      "source": [
        "# TRAIN SET\n",
        "train_smpls = []\n",
        "\n",
        "for i in df_train_cl.index:\n",
        "    if df_train_cl['gold_label'][i] == 'contradiction':\n",
        "        id = 0\n",
        "    elif df_train_cl['gold_label'][i] == 'entailment':\n",
        "        id = 1\n",
        "    elif df_train_cl['gold_label'][i] == 'neutral':\n",
        "        id = 2\n",
        "    input_sample = InputExample(texts=[df_train_cl['sentence1'][i], df_train_cl['sentence2'][i]], label=id)\n",
        "    train_smpls.append(input_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFMg7FqT_vgv"
      },
      "outputs": [],
      "source": [
        "# TEST SET\n",
        "test_smpls = []\n",
        "ids = []\n",
        "\n",
        "for i in df_test_cl.index:\n",
        "    if df_test_cl['gold_label'][i] == 'contradiction':\n",
        "        id = 0\n",
        "    elif df_test_cl['gold_label'][i] == 'entailment':\n",
        "        id = 1\n",
        "    elif df_test_cl['gold_label'][i] == 'neutral':\n",
        "        id = 2\n",
        "    input_sample = InputExample(texts=[df_test_cl['sentence1'][i], df_test_cl['sentence2'][i]], label=id)\n",
        "    test_smpls.append(input_sample)\n",
        "    ids.append(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sOlgRsu_vcO"
      },
      "outputs": [],
      "source": [
        "# DEV SET\n",
        "dev_smpls = []\n",
        "\n",
        "for i in df_dev_cl.index:\n",
        "    if df_dev_cl['gold_label'][i] == 'contradiction':\n",
        "        id = 0\n",
        "    elif df_dev_cl['gold_label'][i] == 'entailment':\n",
        "        id = 1\n",
        "    elif df_dev_cl['gold_label'][i] == 'neutral':\n",
        "        id = 2\n",
        "    input_sample = InputExample(texts=[df_dev_cl['sentence1'][i], df_dev_cl['sentence2'][i]], label=id)\n",
        "    dev_smpls.append(input_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the previous model"
      ],
      "metadata": {
        "id": "1TRxYZRf9Gjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "0cvIO-vt9Gzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training set and define the loss function as the cosine similarity"
      ],
      "metadata": {
        "id": "kz5Knx3Q9SC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DOING IT WITH ALL THE DATASET\n",
        "train_dataloader_cl = DataLoader(train_smpls, shuffle=True, batch_size=train_batch_size)\n",
        "\n",
        "# DOING IT WITH A SUBSET OF THE DATASET\n",
        "# train_dataloader_cl = DataLoader(train_smpls[0:200000], shuffle=True, batch_size=train_batch_size)\n",
        "\n",
        "train_loss_cl = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label_map))"
      ],
      "metadata": {
        "id": "N7-37H6T9SbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the evaluator for the sentence embeddings"
      ],
      "metadata": {
        "id": "e6DJ1AbT-jSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_cl = EmbeddingSimilarityEvaluator.from_input_examples(dev_smpls, batch_size=train_batch_size, name='snli-dev')"
      ],
      "metadata": {
        "id": "b29ssL74-jrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10% of train dataset for warm-up"
      ],
      "metadata": {
        "id": "81UVzazi_Um6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_steps_cl = math.ceil(len(train_dataloader_cl) * num_epochs * 0.1)"
      ],
      "metadata": {
        "id": "SUn7b8IQ_VBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "4TIR5cfc70Hu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa_0LhJk_vY9"
      },
      "outputs": [],
      "source": [
        "save_path_cl = './training_snli_class_'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ow0P5N98RbU"
      },
      "outputs": [],
      "source": [
        "# model.fit(train_objectives=[(train_dataloader_cl, train_loss_cl)],\n",
        "#             evaluator=evaluator_cl,\n",
        "#             epochs=num_epochs,\n",
        "#             evaluation_steps=1000,\n",
        "#             warmup_steps=warmup_steps_cl,\n",
        "#             output_path=save_path_cl\n",
        "#             )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the saved model folder"
      ],
      "metadata": {
        "id": "bxvvlYEZAWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading the stored model from Google Drive ...')\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/training_snli'\n",
        "\n",
        "if os.path.exists(path):\n",
        "    model = SentenceTransformer(path)\n",
        "\n",
        "# model = SentenceTransformer(save_path_cl) # if run the training"
      ],
      "metadata": {
        "id": "DY-hQo5cAXej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8qHUIwl_-F"
      },
      "source": [
        "**Evaluation on SNLI dataset with library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxvA9iEe8RX2"
      },
      "outputs": [],
      "source": [
        "test_eval_cl = EmbeddingSimilarityEvaluator.from_input_examples(test_smpls, batch_size=train_batch_size, name='snli-test')\n",
        "c_s_cl = test_eval_cl(model, output_path=path) # or save_path_cl\n",
        "print('Cosine similarity with the sentence_transformers library = ', c_s_cl)\n",
        "\n",
        "# result with 200000 -> 0.3378714236743856"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C11EGRhZmgXp"
      },
      "source": [
        "**Evaluation on STS benchmark dataset with library**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_s_sts = test_eval(model, output_path=path) # from regression task\n",
        "print('Cosine similarity with the sentence_transformers library = ', c_s_sts)\n",
        "\n",
        "# result with 200000 -> 0.7167475547347155"
      ],
      "metadata": {
        "id": "2QpqTAA1dGW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on SNLI and STS benchmark datasets** (no library)"
      ],
      "metadata": {
        "id": "DT-zzI3re0Hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding sentences"
      ],
      "metadata": {
        "id": "CljlJnzTZbob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_1_snli = model.encode(df_test_cl['sentence1'], convert_to_numpy=True, batch_size=train_batch_size)\n",
        "embed_2_snli = model.encode(df_test_cl['sentence2'], convert_to_numpy=True, batch_size=train_batch_size)\n",
        "\n",
        "embed_1 = model.encode(df_test['sentence_1'], convert_to_numpy=True, batch_size=train_batch_size)\n",
        "embed_2 = model.encode(df_test['sentence_2'], convert_to_numpy=True, batch_size=train_batch_size)"
      ],
      "metadata": {
        "id": "dRzdyv2dZZsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the cosine similarity"
      ],
      "metadata": {
        "id": "mJIQ-KDsaz9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim_cl = 1 - sklearn.metrics.pairwise.paired_cosine_distances(embed_1_snli, embed_2_snli)\n",
        "print('SNLI-test: cosine similarity = ', cos_sim_cl)"
      ],
      "metadata": {
        "id": "lj7xF3ELZZit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim_sts = 1 - sklearn.metrics.pairwise.paired_cosine_distances(embed_1, embed_2)\n",
        "print('STS benchmark: cosine similarity = ', cos_sim_sts)"
      ],
      "metadata": {
        "id": "Xe48tfwzftaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spearmean correlation coefficient"
      ],
      "metadata": {
        "id": "3y7_uhJhfeTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spr_corr_cl = scipy.stats.spearmanr(cos_sim_cl, ids)\n",
        "print('SNLI-test: Spearmean correlation coefficient = ', spr_corr_cl[0])"
      ],
      "metadata": {
        "id": "lCngCYBwfhAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spr_corr_sts = scipy.stats.spearmanr(cos_sim_sts, df_test['score'])\n",
        "print('STS benchmark: Spearmean correlation coefficient = ', spr_corr_sts[0])"
      ],
      "metadata": {
        "id": "yP63EcvIZZX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment:** All the results match each other"
      ],
      "metadata": {
        "id": "s4J_aWodhmin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ka7MTXW3iFLN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XblaOL55NaA"
      },
      "source": [
        "## **SEMANTIC SEARCH**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link to dataset:** https://www.kaggle.com/rmisra/news-category-dataset"
      ],
      "metadata": {
        "id": "tcUrXGwesVOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIgELftc9Rsq"
      },
      "outputs": [],
      "source": [
        "print('Uploading dataset to the session storage ...')\n",
        "\n",
        "file_path = '/content/news.zip'\n",
        "os.path.isfile(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzwW4zZi9Rjv"
      },
      "outputs": [],
      "source": [
        "!unzip news.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_path = '/content/News_Category_Dataset_v2.json'\n",
        "os.path.isfile(news_path)\n",
        "\n",
        "news_set = pd.read_json(news_path, lines=True)"
      ],
      "metadata": {
        "id": "KOjj8QDVtTrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = []\n",
        "\n",
        "with open(news_path) as f:\n",
        "    for line in f:\n",
        "        record = json.loads(line.strip())\n",
        "        # encoding as [headline, short_description]\n",
        "        news.append([record['headline'], record['short_description']])"
      ],
      "metadata": {
        "id": "9Oa2-CrAxYNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the previous saved model to encode the text"
      ],
      "metadata": {
        "id": "UA3vmgnlw25n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = SentenceTransformer(path)\n",
        "embed_news = encoder.encode(news, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "SXK-9oeutTkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm2Uvq0R9m1R"
      },
      "outputs": [],
      "source": [
        "search = input(\"Find close to: \")\n",
        "n_close = 5 # number of similar record\n",
        "\n",
        "embed_query = encoder.encode(search, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim = util.pytorch_cos_sim(embed_query, embed_news)[0]\n",
        "top_close = torch.topk(cos_sim, k=n_close)"
      ],
      "metadata": {
        "id": "OdyvhIZG1-q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Find close to: \", search)\n",
        "\n",
        "print(\"\\nTop \", n_close, \" closer news in the dataset:\")\n",
        "\n",
        "for score, idx in zip(top_close[0], top_close[1]):\n",
        "    print(news[idx], \"(score: {:.4f})\".format(score))"
      ],
      "metadata": {
        "id": "nH8fQxQE1-ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XqtMtuYauuQp"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LAB-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}